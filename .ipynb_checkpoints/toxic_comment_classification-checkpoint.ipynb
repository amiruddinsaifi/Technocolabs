{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSXOwv6tjOs9",
    "outputId": "13f4c22b-5521-4e1e-8a2e-b7ea253dff3b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JlYHvYYC-eac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "pUqTcbHn-ead",
    "outputId": "d9bee7ca-d34c-4032-c67a-d9b54fb023a5",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /content/drive/MyDrive/Technocolabs project/train.csv does not exist: '/content/drive/MyDrive/Technocolabs project/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-154b36c1ad7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Technocolabs project/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/MyDrive/Technocolabs project/train.csv does not exist: '/content/drive/MyDrive/Technocolabs project/train.csv'"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tU2ZbDmI-48l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMpLoXiBEeIV",
    "outputId": "d02cfb6a-4304-4ce7-d9d9-9fe52bff58d3"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "IH4OdBCdreXK",
    "outputId": "2fff5639-123f-4c72-ac99-a95da2096a08"
   },
   "outputs": [],
   "source": [
    "train.comment_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fAciHAo9rrMn",
    "outputId": "78dd45f4-aa26-478f-db72-7ca540eb50a7"
   },
   "outputs": [],
   "source": [
    "train.comment_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "CCKhULF8rrkf",
    "outputId": "9e73c04a-ebee-44bf-dc17-2e3d16c75aa5"
   },
   "outputs": [],
   "source": [
    "train.comment_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbBbi3q6EitM",
    "outputId": "34e866ac-53a1-40a6-f29a-2cc2cd3cbff4"
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qm4Pn4_lrqDy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9I3yk3IEoYb",
    "outputId": "c4690efa-0297-4549-ef9b-f46ea46bd35e"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "widNvzXLt6Nr",
    "outputId": "9698a55d-c07e-4db0-b0ea-e850e6f8a560"
   },
   "outputs": [],
   "source": [
    "train_data_counts=train.iloc[:,2:].sum()\n",
    "train_data_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "0oHfUE2s0PWU",
    "outputId": "2d2a8eee-b601-46af-83eb-c3ef72cfd1cf"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='toxic', data=train)\n",
    "plt.title('toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2JCKIVksn4K",
    "outputId": "fb539e75-8c26-45f4-ef65-27ff0db75cc4"
   },
   "outputs": [],
   "source": [
    "lab=['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "for i in lab:\n",
    "  print(i)\n",
    "  a=train[i].value_counts(normalize=True)\n",
    "  print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "Ro0IHjFDGHMV",
    "outputId": "954a44f9-5f39-4151-fa20-48c92e221b74"
   },
   "outputs": [],
   "source": [
    "# Plot a chart with the following size\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "# Plot a bar chart using the index (category values) and the count of each category. alpha = 0.8 to make the bars more translucent\n",
    "ax = sns.barplot(train_data_counts.index, train_data_counts.values, alpha=0.8)\n",
    "\n",
    "plt.title(\"No. of comments per class\")\n",
    "plt.ylabel('No. of Occurrences', fontsize=12)\n",
    "plt.xlabel('Type ', fontsize=12)\n",
    "\n",
    "#adding the text labels for each bar\n",
    "rects = ax.patches\n",
    "labels = train_data_counts.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "N53crzNLJGTM",
    "outputId": "8ca4e002-f351-4661-a495-186689768992"
   },
   "outputs": [],
   "source": [
    "value_count=[15294,1595,8449,478,7877,1405]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.pie(value_count,labels=lab)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl4lrqtK-eae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "SIZEgNPv-eae",
    "outputId": "6a0ca0bf-cb61-4478-f2fd-0ed5e7b2e0c2"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='severe_toxic',data=train)\n",
    "plt.title('severe_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsUE-FpU16Xn",
    "outputId": "04873cbf-c052-46ac-9d25-bb4f6702b62f"
   },
   "outputs": [],
   "source": [
    "num_rows=len(train)\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVlpl7Be-BpH",
    "outputId": "fd2546aa-329f-4b03-866d-9980cd5f2098"
   },
   "outputs": [],
   "source": [
    "ind = np.arange(6)\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOyxRgI_-b54"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F257z4DL-cVK",
    "outputId": "6fd682af-941d-4b2b-946d-113aa079aeec"
   },
   "outputs": [],
   "source": [
    "li=([train[i].sum()/num_rows*100 for i in lab])\n",
    "li=sorted(li,reverse=True)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "zsUIYpRJ7K7A",
    "outputId": "02d0f2e8-327e-4ae5-dbcb-516ec8c172af"
   },
   "outputs": [],
   "source": [
    "ind = np.arange(6)\n",
    "\n",
    "ax=plt.barh(ind,li)\n",
    "plt.xlabel('Percentage (%)', size=20)\n",
    "plt.xticks(np.arange(0, 30, 5), size=20)\n",
    "plt.title('% of comments in various categories', size=22)\n",
    "plt.yticks(ind, ('Toxic', 'Obscene', 'Insult', 'Severe Toxic', 'Identity Hate', 'Threat', ), size=15)\n",
    "\n",
    "# Invert the graph so that it is in descending order.\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzgM0uRQQ3x9"
   },
   "source": [
    "#Step 2.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k33AjIDFcTn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def other_clean(text):\n",
    "        \"\"\"\n",
    "            Other manual text cleaning techniques\n",
    "        \"\"\"\n",
    "        # Typos, slang and other\n",
    "        sample_typos_slang = {\n",
    "                                \"w/e\": \"whatever\",\n",
    "                                \"usagov\": \"usa government\",\n",
    "                                \"recentlu\": \"recently\",\n",
    "                                \"ph0tos\": \"photos\",\n",
    "                                \"amirite\": \"am i right\",\n",
    "                                \"exp0sed\": \"exposed\",\n",
    "                                \"<3\": \"love\",\n",
    "                                \"luv\": \"love\",\n",
    "                                \"amageddon\": \"armageddon\",\n",
    "                                \"trfc\": \"traffic\",\n",
    "                                \"16yr\": \"16 year\"\n",
    "                                }\n",
    "\n",
    "        # Acronyms\n",
    "        sample_acronyms =  { \n",
    "                            \"mh370\": \"malaysia airlines flight 370\",\n",
    "                            \"okwx\": \"oklahoma city weather\",\n",
    "                            \"arwx\": \"arkansas weather\",    \n",
    "                            \"gawx\": \"georgia weather\",  \n",
    "                            \"scwx\": \"south carolina weather\",  \n",
    "                            \"cawx\": \"california weather\",\n",
    "                            \"tnwx\": \"tennessee weather\",\n",
    "                            \"azwx\": \"arizona weather\",  \n",
    "                            \"alwx\": \"alabama weather\",\n",
    "                            \"usnwsgov\": \"united states national weather service\",\n",
    "                            \"2mw\": \"tomorrow\"\n",
    "                            }\n",
    "\n",
    "        \n",
    "        # Some common abbreviations \n",
    "        sample_abbr = {\n",
    "                        \"$\" : \" dollar \",\n",
    "                        \"€\" : \" euro \",\n",
    "                        \"4ao\" : \"for adults only\",\n",
    "                        \"a.m\" : \"before midday\",\n",
    "                        \"a3\" : \"anytime anywhere anyplace\",\n",
    "                        \"aamof\" : \"as a matter of fact\",\n",
    "                        \"acct\" : \"account\",\n",
    "                        \"adih\" : \"another day in hell\",\n",
    "                        \"afaic\" : \"as far as i am concerned\",\n",
    "                        \"afaict\" : \"as far as i can tell\",\n",
    "                        \"afaik\" : \"as far as i know\",\n",
    "                        \"afair\" : \"as far as i remember\",\n",
    "                        \"afk\" : \"away from keyboard\",\n",
    "                        \"app\" : \"application\",\n",
    "                        \"approx\" : \"approximately\",\n",
    "                        \"apps\" : \"applications\",\n",
    "                        \"asap\" : \"as soon as possible\",\n",
    "                        \"asl\" : \"age, sex, location\",\n",
    "                        \"atk\" : \"at the keyboard\",\n",
    "                        \"ave.\" : \"avenue\",\n",
    "                        \"aymm\" : \"are you my mother\",\n",
    "                        \"ayor\" : \"at your own risk\", \n",
    "                        \"b&b\" : \"bed and breakfast\",\n",
    "                        \"b+b\" : \"bed and breakfast\",\n",
    "                        \"b.c\" : \"before christ\",\n",
    "                        \"b2b\" : \"business to business\",\n",
    "                        \"b2c\" : \"business to customer\",\n",
    "                        \"b4\" : \"before\",\n",
    "                        \"b4n\" : \"bye for now\",\n",
    "                        \"b@u\" : \"back at you\",\n",
    "                        \"bae\" : \"before anyone else\",\n",
    "                        \"bak\" : \"back at keyboard\",\n",
    "                        \"bbbg\" : \"bye bye be good\",\n",
    "                        \"bbc\" : \"british broadcasting corporation\",\n",
    "                        \"bbias\" : \"be back in a second\",\n",
    "                        \"bbl\" : \"be back later\",\n",
    "                        \"bbs\" : \"be back soon\",\n",
    "                        \"be4\" : \"before\",\n",
    "                        \"bfn\" : \"bye for now\",\n",
    "                        \"blvd\" : \"boulevard\",\n",
    "                        \"bout\" : \"about\",\n",
    "                        \"brb\" : \"be right back\",\n",
    "                        \"bros\" : \"brothers\",\n",
    "                        \"brt\" : \"be right there\",\n",
    "                        \"bsaaw\" : \"big smile and a wink\",\n",
    "                        \"btw\" : \"by the way\",\n",
    "                        \"bwl\" : \"bursting with laughter\",\n",
    "                        \"c/o\" : \"care of\",\n",
    "                        \"cet\" : \"central european time\",\n",
    "                        \"cf\" : \"compare\",\n",
    "                        \"cia\" : \"central intelligence agency\",\n",
    "                        \"csl\" : \"can not stop laughing\",\n",
    "                        \"cu\" : \"see you\",\n",
    "                        \"cul8r\" : \"see you later\",\n",
    "                        \"cv\" : \"curriculum vitae\",\n",
    "                        \"cwot\" : \"complete waste of time\",\n",
    "                        \"cya\" : \"see you\",\n",
    "                        \"cyt\" : \"see you tomorrow\",\n",
    "                        \"dae\" : \"does anyone else\",\n",
    "                        \"dbmib\" : \"do not bother me i am busy\",\n",
    "                        \"diy\" : \"do it yourself\",\n",
    "                        \"dm\" : \"direct message\",\n",
    "                        \"dwh\" : \"during work hours\",\n",
    "                        \"e123\" : \"easy as one two three\",\n",
    "                        \"eet\" : \"eastern european time\",\n",
    "                        \"eg\" : \"example\",\n",
    "                        \"embm\" : \"early morning business meeting\",\n",
    "                        \"encl\" : \"enclosed\",\n",
    "                        \"encl.\" : \"enclosed\",\n",
    "                        \"etc\" : \"and so on\",\n",
    "                        \"faq\" : \"frequently asked questions\",\n",
    "                        \"fawc\" : \"for anyone who cares\",\n",
    "                        \"fb\" : \"facebook\",\n",
    "                        \"fc\" : \"fingers crossed\",\n",
    "                        \"fig\" : \"figure\",\n",
    "                        \"fimh\" : \"forever in my heart\", \n",
    "                        \"ft.\" : \"feet\",\n",
    "                        \"ft\" : \"featuring\",\n",
    "                        \"ftl\" : \"for the loss\",\n",
    "                        \"ftw\" : \"for the win\",\n",
    "                        \"fwiw\" : \"for what it is worth\",\n",
    "                        \"fyi\" : \"for your information\",\n",
    "                        \"g9\" : \"genius\",\n",
    "                        \"gahoy\" : \"get a hold of yourself\",\n",
    "                        \"gal\" : \"get a life\",\n",
    "                        \"gcse\" : \"general certificate of secondary education\",\n",
    "                        \"gfn\" : \"gone for now\",\n",
    "                        \"gg\" : \"good game\",\n",
    "                        \"gl\" : \"good luck\",\n",
    "                        \"glhf\" : \"good luck have fun\",\n",
    "                        \"gmt\" : \"greenwich mean time\",\n",
    "                        \"gmta\" : \"great minds think alike\",\n",
    "                        \"gn\" : \"good night\",\n",
    "                        \"g.o.a.t\" : \"greatest of all time\",\n",
    "                        \"goat\" : \"greatest of all time\",\n",
    "                        \"goi\" : \"get over it\",\n",
    "                        \"gps\" : \"global positioning system\",\n",
    "                        \"gr8\" : \"great\",\n",
    "                        \"gratz\" : \"congratulations\",\n",
    "                        \"gyal\" : \"girl\",\n",
    "                        \"h&c\" : \"hot and cold\",\n",
    "                        \"hp\" : \"horsepower\",\n",
    "                        \"hr\" : \"hour\",\n",
    "                        \"hrh\" : \"his royal highness\",\n",
    "                        \"ht\" : \"height\",\n",
    "                        \"ibrb\" : \"i will be right back\",\n",
    "                        \"ic\" : \"i see\",\n",
    "                        \"icq\" : \"i seek you\",\n",
    "                        \"icymi\" : \"in case you missed it\",\n",
    "                        \"idc\" : \"i do not care\",\n",
    "                        \"idgadf\" : \"i do not give a damn fuck\",\n",
    "                        \"idgaf\" : \"i do not give a fuck\",\n",
    "                        \"idk\" : \"i do not know\",\n",
    "                        \"ie\" : \"that is\",\n",
    "                        \"i.e\" : \"that is\",\n",
    "                        \"ifyp\" : \"i feel your pain\",\n",
    "                        \"IG\" : \"instagram\",\n",
    "                        \"iirc\" : \"if i remember correctly\",\n",
    "                        \"ilu\" : \"i love you\",\n",
    "                        \"ily\" : \"i love you\",\n",
    "                        \"imho\" : \"in my humble opinion\",\n",
    "                        \"imo\" : \"in my opinion\",\n",
    "                        \"imu\" : \"i miss you\",\n",
    "                        \"iow\" : \"in other words\",\n",
    "                        \"irl\" : \"in real life\",\n",
    "                        \"j4f\" : \"just for fun\",\n",
    "                        \"jic\" : \"just in case\",\n",
    "                        \"jk\" : \"just kidding\",\n",
    "                        \"jsyk\" : \"just so you know\",\n",
    "                        \"l8r\" : \"later\",\n",
    "                        \"lb\" : \"pound\",\n",
    "                        \"lbs\" : \"pounds\",\n",
    "                        \"ldr\" : \"long distance relationship\",\n",
    "                        \"lmao\" : \"laugh my ass off\",\n",
    "                        \"lmfao\" : \"laugh my fucking ass off\",\n",
    "                        \"lol\" : \"laughing out loud\",\n",
    "                        \"ltd\" : \"limited\",\n",
    "                        \"ltns\" : \"long time no see\",\n",
    "                        \"m8\" : \"mate\",\n",
    "                        \"mf\" : \"motherfucker\",\n",
    "                        \"mfs\" : \"motherfuckers\",\n",
    "                        \"mfw\" : \"my face when\",\n",
    "                        \"mofo\" : \"motherfucker\",\n",
    "                        \"mph\" : \"miles per hour\",\n",
    "                        \"mr\" : \"mister\",\n",
    "                        \"mrw\" : \"my reaction when\",\n",
    "                        \"ms\" : \"miss\",\n",
    "                        \"mte\" : \"my thoughts exactly\",\n",
    "                        \"nagi\" : \"not a good idea\",\n",
    "                        \"nbc\" : \"national broadcasting company\",\n",
    "                        \"nbd\" : \"not big deal\",\n",
    "                        \"nfs\" : \"not for sale\",\n",
    "                        \"ngl\" : \"not going to lie\",\n",
    "                        \"nhs\" : \"national health service\",\n",
    "                        \"nrn\" : \"no reply necessary\",\n",
    "                        \"nsfl\" : \"not safe for life\",\n",
    "                        \"nsfw\" : \"not safe for work\",\n",
    "                        \"nth\" : \"nice to have\",\n",
    "                        \"nvr\" : \"never\",\n",
    "                        \"nyc\" : \"new york city\",\n",
    "                        \"oc\" : \"original content\",\n",
    "                        \"og\" : \"original\",\n",
    "                        \"ohp\" : \"overhead projector\",\n",
    "                        \"oic\" : \"oh i see\",\n",
    "                        \"omdb\" : \"over my dead body\",\n",
    "                        \"omg\" : \"oh my god\",\n",
    "                        \"omw\" : \"on my way\",\n",
    "                        \"p.a\" : \"per annum\",\n",
    "                        \"p.m\" : \"after midday\",\n",
    "                        \"pm\" : \"prime minister\",\n",
    "                        \"poc\" : \"people of color\",\n",
    "                        \"pov\" : \"point of view\",\n",
    "                        \"pp\" : \"pages\",\n",
    "                        \"ppl\" : \"people\",\n",
    "                        \"prw\" : \"parents are watching\",\n",
    "                        \"ps\" : \"postscript\",\n",
    "                        \"pt\" : \"point\",\n",
    "                        \"ptb\" : \"please text back\",\n",
    "                        \"pto\" : \"please turn over\",\n",
    "                        \"qpsa\" : \"what happens\", #\"que pasa\",\n",
    "                        \"ratchet\" : \"rude\",\n",
    "                        \"rbtl\" : \"read between the lines\",\n",
    "                        \"rlrt\" : \"real life retweet\", \n",
    "                        \"rofl\" : \"rolling on the floor laughing\",\n",
    "                        \"roflol\" : \"rolling on the floor laughing out loud\",\n",
    "                        \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
    "                        \"rt\" : \"retweet\",\n",
    "                        \"ruok\" : \"are you ok\",\n",
    "                        \"sfw\" : \"safe for work\",\n",
    "                        \"sk8\" : \"skate\",\n",
    "                        \"smh\" : \"shake my head\",\n",
    "                        \"sq\" : \"square\",\n",
    "                        \"srsly\" : \"seriously\", \n",
    "                        \"ssdd\" : \"same stuff different day\",\n",
    "                        \"tbh\" : \"to be honest\",\n",
    "                        \"tbs\" : \"tablespooful\",\n",
    "                        \"tbsp\" : \"tablespooful\",\n",
    "                        \"tfw\" : \"that feeling when\",\n",
    "                        \"thks\" : \"thank you\",\n",
    "                        \"tho\" : \"though\",\n",
    "                        \"thx\" : \"thank you\",\n",
    "                        \"tia\" : \"thanks in advance\",\n",
    "                        \"til\" : \"today i learned\",\n",
    "                        \"tl;dr\" : \"too long i did not read\",\n",
    "                        \"tldr\" : \"too long i did not read\",\n",
    "                        \"tmb\" : \"tweet me back\",\n",
    "                        \"tntl\" : \"trying not to laugh\",\n",
    "                        \"ttyl\" : \"talk to you later\",\n",
    "                        \"u\" : \"you\",\n",
    "                        \"u2\" : \"you too\",\n",
    "                        \"u4e\" : \"yours for ever\",\n",
    "                        \"utc\" : \"coordinated universal time\",\n",
    "                        \"w/\" : \"with\",\n",
    "                        \"w/o\" : \"without\",\n",
    "                        \"w8\" : \"wait\",\n",
    "                        \"wassup\" : \"what is up\",\n",
    "                        \"wb\" : \"welcome back\",\n",
    "                        \"wtf\" : \"what the fuck\",\n",
    "                        \"wtg\" : \"way to go\",\n",
    "                        \"wtpa\" : \"where the party at\",\n",
    "                        \"wuf\" : \"where are you from\",\n",
    "                        \"wuzup\" : \"what is up\",\n",
    "                        \"wywh\" : \"wish you were here\",\n",
    "                        \"yd\" : \"yard\",\n",
    "                        \"ygtr\" : \"you got that right\",\n",
    "                        \"ynk\" : \"you never know\",\n",
    "                        \"zzz\" : \"sleeping bored and tired\"\n",
    "                        }\n",
    "            \n",
    "        sample_typos_slang_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\\w)')\n",
    "        sample_acronyms_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\\w)')\n",
    "        sample_abbr_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\\w)')\n",
    "        \n",
    "        text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)\n",
    "        text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)\n",
    "        text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRchZvRnFqbr"
   },
   "outputs": [],
   "source": [
    "train['comment_text']=train['comment_text'].apply(lambda x: other_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "fq_fDBqaGeC3",
    "outputId": "5ad4832f-0785-469c-efc6-4b5f8a1e5240"
   },
   "outputs": [],
   "source": [
    "train['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "1-RAjeefsHI5",
    "outputId": "cc9cbade-92da-45eb-b1c3-def41125a6f7"
   },
   "outputs": [],
   "source": [
    "# Text preprocessing steps - remove numbers, capital letters, punctuation, '\\n'\n",
    "import re\n",
    "import string\n",
    "\n",
    "# remove all numbers with letters attached to them\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "# '[%s]' % re.escape(string.punctuation),' ' - replace punctuation with white space\n",
    "# .lower() - convert all strings to lowercase \n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "# Remove all '\\n' in the string and replace it with a space\n",
    "remove_n = lambda x: re.sub(\"\\n\", \" \", x)\n",
    "\n",
    "# Remove all non-ascii characters \n",
    "remove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n",
    "\n",
    "# Apply all the lambda functions wrote previously through .map on the comments column\n",
    "train['comment_text'] = train['comment_text'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)\n",
    "\n",
    "train['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "pcIU1vSrsHT5",
    "outputId": "50f26f90-ae4e-4d88-bd24-517723f3a53f"
   },
   "outputs": [],
   "source": [
    "train_tox =train.loc[:,['id','comment_text','toxic']]\n",
    "train_tox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50ugcle8sHV8"
   },
   "outputs": [],
   "source": [
    "train_sev = train.loc[:,['id','comment_text','severe_toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zti7PTfDdHK"
   },
   "outputs": [],
   "source": [
    "train_obs = train.loc[:,['id','comment_text','obscene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6vs8WrMDdKM"
   },
   "outputs": [],
   "source": [
    "train_thr = train.loc[:,['id','comment_text','threat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvlj2ub1DdMr"
   },
   "outputs": [],
   "source": [
    "train_ins = train.loc[:,['id','comment_text','insult']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpMYzQp5DdOl"
   },
   "outputs": [],
   "source": [
    "train_ide = train.loc[:,['id','comment_text','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irPp1iyfsHZy",
    "outputId": "5b89be20-bea9-480b-a171-35ce81989c5f"
   },
   "outputs": [],
   "source": [
    "sum(train_tox['toxic']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2x7fEVVuPwx",
    "outputId": "4047f4a2-0b01-4ace-de5d-032acc1895a5"
   },
   "outputs": [],
   "source": [
    "train_tox_1 = train_tox[train_tox['toxic'] == 1].iloc[0:5000,:]\n",
    "train_tox_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-sLHCyQWoBE"
   },
   "outputs": [],
   "source": [
    "train_tox_0 = train_tox[train_tox['toxic'] == 0].iloc[0:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmITbUo6WoSS",
    "outputId": "0438e532-f411-4edd-90e4-275de0a289a8"
   },
   "outputs": [],
   "source": [
    "train_tox_done = pd.concat([train_tox_1, train_tox_0], axis=0)\n",
    "train_tox_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuFslaaGWoT5",
    "outputId": "659cd2a1-4148-44d9-9641-67c0a607ba5a"
   },
   "outputs": [],
   "source": [
    "train_sev[train_sev['severe_toxic'] == 1].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzSDkyYfWoaN",
    "outputId": "b7d47af3-946c-4adc-c347-5cc613b78144"
   },
   "outputs": [],
   "source": [
    "train_sev_1 = train_sev[train_sev['severe_toxic'] == 1].iloc[0:1595,:]\n",
    "train_sev_0 = train_sev[train_sev['severe_toxic'] == 0].iloc[0:1595,:]\n",
    "train_sev_done = pd.concat([train_sev_1, train_sev_0], axis=0)\n",
    "train_sev_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H79kI9lqXcfA",
    "outputId": "13288ea9-15cb-4f2d-fee2-2b5fe0f09a32"
   },
   "outputs": [],
   "source": [
    "train_obs[train_obs['obscene'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhfXjiTD1CW_",
    "outputId": "462b8682-2d70-4286-abd2-756cf297a2db"
   },
   "outputs": [],
   "source": [
    "train_obs_1 = train_obs[train_obs['obscene'] == 1].iloc[0:5000,:]\n",
    "train_obs_0 = train_obs[train_obs['obscene'] == 0].iloc[0:5000,:]\n",
    "train_obs_done = pd.concat([train_obs_1, train_obs_0], axis=0)\n",
    "train_obs_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZL8VqlaX68DN",
    "outputId": "7416b89a-96cd-4df6-c014-1641f45c099e"
   },
   "outputs": [],
   "source": [
    "train_thr[train_thr['threat'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaAZNAKrXmtY",
    "outputId": "0c2f8572-66aa-438a-bac9-7a1064a9a93c"
   },
   "outputs": [],
   "source": [
    "train_thr_1 = train_thr[train_thr['threat'] == 1].iloc[0:478,:]\n",
    "\n",
    "# We include 1912 comments that have no threat so that the data with threat (478) will represent 20% of the dataset.\n",
    "train_thr_0 = train_thr[train_thr['threat'] == 0].iloc[0:1912,:]  \n",
    "train_thr_done = pd.concat([train_thr_1, train_thr_0], axis=0)\n",
    "train_thr_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHUCxh0IXmxJ",
    "outputId": "570cec48-ad56-44bf-def2-55ab9211bdb8"
   },
   "outputs": [],
   "source": [
    "train_ins[train_ins['insult'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uG2iruNHXm0Q",
    "outputId": "61a61938-b2a1-4068-fb39-6afec94e05bd"
   },
   "outputs": [],
   "source": [
    "train_ins_1 = train_ins[train_ins['insult'] == 1].iloc[0:5000,:]\n",
    "train_ins_0 = train_ins[train_ins['insult'] == 0].iloc[0:5000,:]\n",
    "train_ins_done = pd.concat([train_ins_1, train_ins_0], axis=0)\n",
    "train_ins_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKZFxC4rXm2N",
    "outputId": "48d9e97a-ab40-436c-c8af-1bcb4348be93"
   },
   "outputs": [],
   "source": [
    "train_ide[train_ide['identity_hate'] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLkbEou1Xm45",
    "outputId": "c113f4c2-f91d-49a4-9506-8031be48db5c"
   },
   "outputs": [],
   "source": [
    "train_ide_1 = train_ide[train_ide['identity_hate'] == 1].iloc[0:1405,:] # 20%\n",
    "train_ide_0 = train_ide[train_ide['identity_hate'] == 0].iloc[0:5620,:] # 80%\n",
    "train_ide_done = pd.concat([train_ide_1, train_ide_0], axis=0)\n",
    "train_ide_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nP333Jm8X03G"
   },
   "outputs": [],
   "source": [
    "# Import packages for pre-processing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Import tools to split data and evaluate model performance\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from nltk.corpus import stopwords  # Remove useless words\n",
    "from nltk.stem.lancaster import LancasterStemmer  # Convert words to base form; aggressive\n",
    "\n",
    "# Import packages that help us to create document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Import ML algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNflGubSX1N6"
   },
   "outputs": [],
   "source": [
    "def cv_tf_train_test(df_done,label,vectorizer,ngram):\n",
    "\n",
    "    ''' Train/Test split'''\n",
    "    # Split the data into X and y data sets\n",
    "    X = df_done.comment_text\n",
    "    y = df_done[label]\n",
    "\n",
    "    # Split our data into training and test data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    ''' Count Vectorizer/TF-IDF '''\n",
    "\n",
    "    # Create a Vectorizer object and remove stopwords from the table\n",
    "    cv1 = vectorizer(ngram_range=(ngram), stop_words='english')\n",
    "    \n",
    "    X_train_cv1 = cv1.fit_transform(X_train) # Learn the vocabulary dictionary and return term-document matrix\n",
    "    X_test_cv1  = cv1.transform(X_test)      # Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "    \n",
    "    # Output a Dataframe of the CountVectorizer with unique words as the labels\n",
    "    # test = pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names())\n",
    "        \n",
    "    ''' Initialize all model objects and fit the models on the training data '''\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_cv1, y_train)\n",
    "    print('lr done')\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_cv1, y_train)\n",
    "    print('knn done')\n",
    "\n",
    "    bnb = BernoulliNB()\n",
    "    bnb.fit(X_train_cv1, y_train)\n",
    "    print('bnb done')\n",
    "    \n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_cv1, y_train)\n",
    "    print('mnb done')\n",
    "\n",
    "    svm_model = LinearSVC()\n",
    "    svm_model.fit(X_train_cv1, y_train)\n",
    "    print(\"svm done\")\n",
    "\n",
    "    randomforest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    randomforest.fit(X_train_cv1, y_train)\n",
    "    print('rdf done')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Create a list of F1 score of all models \n",
    "    f1_score_data = {'F1 Score':[f1_score(lr.predict(X_test_cv1), y_test), f1_score(knn.predict(X_test_cv1), y_test), \n",
    "                                f1_score(bnb.predict(X_test_cv1), y_test), f1_score(mnb.predict(X_test_cv1), y_test),\n",
    "                                f1_score(svm_model.predict(X_test_cv1), y_test), f1_score(randomforest.predict(X_test_cv1), y_test)]} \n",
    "                          \n",
    "    # Create DataFrame with the model names as column labels\n",
    "    df_f1 = pd.DataFrame(f1_score_data, index=['Log Regression','KNN', 'BernoulliNB', 'MultinomialNB', 'SVM', 'Random Forest'])  \n",
    "\n",
    "    # Cross validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    cross_validation = cross_val_score(estimator = lr, X = X_train_cv1,y = y_train, cv = 10)\n",
    "    #print(\"Cross validation accuracy of lr_model = \", cross_validation)\n",
    "    print(\"\\nCross validation mean accuracy of lr_model = \", cross_validation.mean())\n",
    "    \n",
    "    cross_validation = cross_val_score(estimator = knn, X = X_train_cv1,y = y_train, cv = 10)\n",
    "    #print(\"Cross validation accuracy of knn_model = \", cross_validation)\n",
    "    print(\"\\nCross validation mean accuracy of knn_model = \", cross_validation.mean())\n",
    "    \n",
    "    cross_validation = cross_val_score(estimator = bnb, X = X_train_cv1,y = y_train, cv = 10)\n",
    "    #print(\"Cross validation accuracy of bnb_model = \", cross_validation)\n",
    "    print(\"\\nCross validation mean accuracy of bnb_model = \", cross_validation.mean())\n",
    "    \n",
    "    cross_validation = cross_val_score(estimator =mnb , X = X_train_cv1,y = y_train, cv = 10)\n",
    "    #print(\"Cross validation accuracy of mnb_model = \", cross_validation)\n",
    "    print(\"\\nCross validation mean accuracy of mnb_model = \", cross_validation.mean())\n",
    "    \n",
    "    cross_validation = cross_val_score(estimator = svm_model, X = X_train_cv1,y = y_train, cv = 10)\n",
    "    #print(\"Cross validation accuracy of svm_model = \", cross_validation)\n",
    "    print(\"\\nCross validation mean accuracy of svm_model = \", cross_validation.mean())\n",
    "    \n",
    "    cross_validation = cross_val_score(estimator = randomforest, X = X_train_cv1,y = y_train, cv = 10)\n",
    "    #print(\"Cross validation accuracy of randomforest_model = \", cross_validation)\n",
    "    print(\"\\nCross validation mean accuracy of randomforest_model = \", cross_validation.mean())   \n",
    "\n",
    "    return df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "3BHqAa6jX1Ps",
    "outputId": "3659e50d-aacd-4651-bb22-6dea14d45434"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "df_tox_cv = cv_tf_train_test(train_tox_done, 'toxic', TfidfVectorizer, (1,1))\n",
    "df_tox_cv.rename(columns={'F1 Score': 'F1 Score(toxic)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_tox_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "AjP0jo6Hc9Og",
    "outputId": "796437d3-eb65-46ec-9d01-0cab463eb167"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_tox_cv = cv_tf_train_test(train_tox_done, 'toxic', TfidfVectorizer, (1,1))\n",
    "df_tox_cv.rename(columns={'F1 Score': 'F1 Score(toxic)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_tox_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "SxArrX6Xc9S_",
    "outputId": "24e6e2d8-b58c-4a25-cdbc-eff884bf3830"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_sev_cv = cv_tf_train_test(train_sev_done, 'severe_toxic', TfidfVectorizer, (1,1))\n",
    "df_sev_cv.rename(columns={'F1 Score': 'F1 Score(severe_toxic)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_sev_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "R3edNvpGc9VN",
    "outputId": "fe75406e-4eec-45df-b99d-460342116ba1"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_obs_cv = cv_tf_train_test(train_obs_done, 'obscene', TfidfVectorizer, (1,1))\n",
    "df_obs_cv.rename(columns={'F1 Score': 'F1 Score(obscene)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_obs_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "uLWQDLcic9Zp",
    "outputId": "b53be805-ed83-4fbf-f0fc-cdb7f5884bcb"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_thr_cv = cv_tf_train_test(train_thr_done, 'threat', TfidfVectorizer, (1,1))\n",
    "df_thr_cv.rename(columns={'F1 Score': 'F1 Score(threat)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_thr_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "eJSjcuFrc9b3",
    "outputId": "1f492ea8-ea44-4741-a8ee-afad42466f18"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_ins_cv = cv_tf_train_test(train_ins_done, 'insult', TfidfVectorizer, (1,1))\n",
    "df_ins_cv.rename(columns={'F1 Score': 'F1 Score(insult)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_ins_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "ibnym8gyc9fE",
    "outputId": "7b9977ca-93cf-4303-9974-09fb96845e36"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df_ide_cv = cv_tf_train_test(train_ide_done, 'identity_hate', TfidfVectorizer, (1,1))\n",
    "df_ide_cv.rename(columns={'F1 Score': 'F1 Score(identity_hate)'}, inplace=True)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "total = 'Time taken: {} seconds'.format(t1-t0)\n",
    "print(total)\n",
    "\n",
    "df_ide_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "GlmVXAYWc9if",
    "outputId": "8ee7f58b-f6f6-44fc-f2b0-612051a839d8"
   },
   "outputs": [],
   "source": [
    "# Let's combine the dataframes into a master dataframe to compare F1 scores across all categories.\n",
    "f1_all = pd.concat([df_tox_cv, df_sev_cv, df_obs_cv, df_ins_cv, df_thr_cv, df_ide_cv], axis=1)\n",
    "f1_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "C_8SmMbcc9ki",
    "outputId": "db522e11-241c-44c0-98e0-122232958525"
   },
   "outputs": [],
   "source": [
    "f1_all_trp = f1_all.transpose()\n",
    "f1_all_trp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "MIsn1XHoc9oE",
    "outputId": "f5d3d0ab-ed40-4614-be32-efc805815a79"
   },
   "outputs": [],
   "source": [
    "f1_all_trp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqrvVD09cC5A",
    "outputId": "a4214774-0d94-4c1b-f5fb-c199d64e78bc"
   },
   "outputs": [],
   "source": [
    "# we can in the above table the maximum accurecy is given by SVM modal\n",
    "f1_all_trp['SVM'].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGX0ESC7scKg",
    "outputId": "b2fce056-1616-4adf-eae6-e0854181433e"
   },
   "outputs": [],
   "source": [
    "f1_all_trp['Random Forest'].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbtZdRpSkc5v",
    "outputId": "79fb5936-5e6a-4e74-c1b8-02ecd08efa7b"
   },
   "outputs": [],
   "source": [
    "X = train_tox_done.comment_text\n",
    "y = train_tox_done['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initiate a Tfidf vectorizer\n",
    "tfv = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "X_train_fit = tfv.fit_transform(X_train)  # Convert the X data into a document term matrix dataframe\n",
    "X_test_fit = tfv.transform(X_test)  # Converts the X_test comments into Vectorized format\n",
    "\n",
    "randomforest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train our SVM model with the X training data converted into Count Vectorized format with the Y training data\n",
    "randomforest.fit(X_train_fit, y_train)\n",
    "randomforest.predict(X_test_fit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtuDsurqnKF2",
    "outputId": "4eea1114-a2a6-40b6-fb0f-bcbe5ce02fae"
   },
   "outputs": [],
   "source": [
    "# Sample Prediction\n",
    "comment1 = ['You piece of shit']\n",
    "comment2 = ['What is up garden apple doing']\n",
    "\n",
    "comment1_vect = tfv.transform(comment1)\n",
    "randomforest.predict_proba(comment1_vect)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvmxq0ttnXF5",
    "outputId": "71603677-76a2-4f85-e37f-2a0f91d4b7d4"
   },
   "outputs": [],
   "source": [
    "comment2_vect = tfv.transform(comment2)\n",
    "randomforest.predict_proba(comment2_vect)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXG2ilPqsJDk"
   },
   "source": [
    "# Pickling trained RandomForest models for all categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKHfmFGfsUrL"
   },
   "source": [
    "##We choose Random Forest instead of LinearSVC although the latter performs well, as RDF has predict_proba function and LinearSVC does not. We need to output a probability score for each comment, remember?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ghiuq0VnXIK"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_aZvfD8sDat"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "NOTE: This step has already been done for you. The pickled files are included in the github. Just for further reference.\n",
    "You do NOT have to run this cell.\n",
    "'''\n",
    "\n",
    "def pickle_model(df, label):\n",
    "    \n",
    "    X = df.comment_text\n",
    "    y = df[label]\n",
    "\n",
    "    # Initiate a Tfidf vectorizer\n",
    "    tfv = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "    \n",
    "    # Convert the X data into a document term matrix dataframe\n",
    "    X_vect = tfv.fit_transform(X)  \n",
    "    \n",
    "    # saves the column labels (ie. the vocabulary)\n",
    "    # wb means Writing to the file in Binary mode, written in byte objects\n",
    "    with open(r\"{}.pkl\".format(label + '_vect'), \"wb\") as f:   \n",
    "        pickle.dump(tfv, f)   \n",
    "        \n",
    "    randomforest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    randomforest.fit(X_vect, y)\n",
    "\n",
    "    # Create a new pickle file based on random forest\n",
    "    with open(r\"{}.pkl\".format(label + '_model'), \"wb\") as f:  \n",
    "        pickle.dump(randomforest, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5V1LrXqsDd4"
   },
   "outputs": [],
   "source": [
    "datalist = [train_tox_done, train_sev_done, train_obs_done, train_ins_done, train_thr_done, train_ide_done]\n",
    "label = ['toxic', 'severe_toxic', 'obscene', 'insult', 'threat', 'identity_hate']\n",
    "\n",
    "for i,j in zip(datalist,label):\n",
    "    pickle_model(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPydU7x5sDgi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Cay-bA1sDi0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayP3SMdqsDmd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rh0Kq9jgnXLk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "toxic comment classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
